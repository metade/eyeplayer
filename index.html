<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Eyeplayer : Control stuff with your webcam" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">
    <style>
      div#videoContainer {
        height: 480px;
        max-width: 1024px;
        position: relative;
      }
      canvas#overlay {
        width: 100%;
        position: absolute;
      }
      video {
        width: 100%;
        position: absolute;
      }
    </style>

    <title>Eyeplayer</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/sidekickstudios/eyeplayer">View on GitHub</a>

          <a href="/">
            <h1 id="project_title">Eyeplayer</h1>
          </a>
          <h2 id="project_tagline">Control stuff with your webcam</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/sidekickstudios/eyeplayer/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/sidekickstudios/eyeplayer/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>Demonstration</h3>

        <div id="videoContainer">
          <video id="inputVideo" autoplay></video>
          <canvas id="overlay"></canvas>
        </div>

        <h3>About this demonstration</h3>
        <p>This is an example of detecting a user blinking with a webcam.</p>
        <p>It uses the following approach:</p>
        <ul>
          <li>the user's face position is determined using the <a href="https://github.com/auduno/headtrackr/">headtrackr</a> library</li>
          <li>from this the user's eyes region position is estimated (i.e. somewhere in the middle of the face.)</li>
          <li>we then use a blob motion detection technique based on the approach from the Flash <a href="https://github.com/og2t/HiSlope">HiSlope</a> library.</li>
          <li>if there are two blobs of motion in the eye region that are placed on opposite sides of the region then we trigger a blink</li>
        </ul>

        <h3>Usage example</h3>
        <pre><code>
          &lt;script data-main="javascripts/eyePlayer.min.js" src="javascripts/require.js"&gt;&lt;/script&gt;
          &lt;script type="text/javascript"&gt;
            var videoInput = document.getElementById('inputVideo');
            var canvasOutput = document.getElementById('overlay');

            require(['eyePlayer'], function(eyePlayer) {
              eyeplayer = new eyePlayer();
              eyeplayer.init(videoInput, canvasOutput);
              eyeplayer.start();
            });

            document.addEventListener('blinkEvent', function() {
              /* DO SOMETHING FUN WHEN THE USER BLINKS */
            });
            document.addEventListener('eyeTrackedEvent', function(event) {
              /* DO SOMETHING FUN WHEN THE USER'S HEAD IS FOUND */
              console.log(event.face);
              console.log(event.eyes);
            });
          &lt;/script&gt;
        </code></pre>

        <p>View source of this page to see a more complete example</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Eyeplayer maintained by <a href="https://github.com/sidekickstudios">sidekickstudios</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    <script data-main="javascripts/eyePlayer.min.js" src="javascripts/require.js"></script>
    <script type="text/javascript">
      var videoInput = document.getElementById('inputVideo');
      var canvasOutput = document.getElementById('overlay');

      var ctx = canvasOutput.getContext('2d');
      var countdown = 0;

      var glassesImg = new Image();
      glassesImg.src = "images/glasses.svg";

      var sounds = {}, audioFiles = ['wob'];
      for (var i=0; i<audioFiles.length; i++) {
        name = audioFiles[i];
        sounds[name] = new Audio();
        sounds[name].src = "sounds/" + name + ".mp3";
      }

      function drawFace(face) {
        ctx.save();
        ctx.translate(face.x, face.y);
        if (face.angle) { ctx.rotate(face.angle); }
        ctx.strokeStyle = '#000000';

        ctx.beginPath();
        ctx.lineWidth = face.width/20;
        ctx.arc(0, 0, face.width/2, 0, Math.PI*2);
        ctx.closePath();
        ctx.stroke();

        ctx.restore();
      }

      function drawEyes(eyes) {
        ctx.save();
        ctx.translate(eyes.x, eyes.y);
        if (eyes.angle) { ctx.rotate(eyes.angle); }
        var w = eyes.width * 0.8;
        ctx.drawImage(glassesImg, -w, -w, w*2, w*2);
        ctx.restore();
      }

      function playSoundIfPaused(name) {
        if (sounds[name].paused) {
          sounds[name].play();
        }
      }

      document.addEventListener('blinkEvent', function() {
        if (countdown == 0) {
          playSoundIfPaused('wob');
          countdown = 5;
        }
      });
      document.addEventListener('eyeTrackedEvent', function(event) {
        drawFace(event.face);
        drawEyes(event.eyes);

        if (countdown > 0) {
          ctx.font="100px Georgia";
          ctx.fillText("BLINK", 0, canvasOutput.height/2);
          countdown -= 1;
        }
      });

      require(['eyePlayer'], function(eyePlayer) {
        eyeplayer = new eyePlayer();
        eyeplayer.init(videoInput, canvasOutput);
        eyeplayer.start();
      });
     </script>
  </body>
</html>
